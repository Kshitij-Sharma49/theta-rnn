{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Create a new DataFrame considering only 'timestamp' and 'valueTfuel'\n",
        "considered_df = df[['timestamp', 'valueTfuel']].copy()"
      ],
      "metadata": {
        "id": "jlTNRFulOR9G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "considered_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH-CgsMTOUeB",
        "outputId": "0fbce0e4-09af-4231-c3aa-50621350fe8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   timestamp   100 non-null    int64  \n",
            " 1   valueTfuel  86 non-null     float64\n",
            "dtypes: float64(1), int64(1)\n",
            "memory usage: 1.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "def predict_value_after_months(data_csv, n_months_ahead):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(data_csv)\n",
        "\n",
        "    # Create a new DataFrame considering only 'timestamp' and 'valueTfuel'\n",
        "    considered_df = df[['timestamp', 'valueTfuel']].copy()\n",
        "\n",
        "    # Remove rows with null values in the considered DataFrame\n",
        "    considered_df.dropna(inplace=True)\n",
        "\n",
        "    # Perform log transformation on 'valueTfuel'\n",
        "    considered_df['log_valueTfuel'] = np.log1p(considered_df['valueTfuel'])\n",
        "\n",
        "    # Remove rows with log_Tfuel = -inf\n",
        "    considered_df = considered_df[considered_df['log_valueTfuel'] != -np.inf]\n",
        "\n",
        "    # Create a new DataFrame with 'timestamp' and 'log_valueTfuel'\n",
        "    final_df = considered_df[['timestamp', 'log_valueTfuel']].copy()\n",
        "\n",
        "    # Convert the 'timestamp' column to datetime type\n",
        "    final_df['timestamp'] = pd.to_datetime(final_df['timestamp'])\n",
        "\n",
        "    # Sort the DataFrame by 'timestamp'\n",
        "    final_df.sort_values('timestamp', inplace=True)\n",
        "\n",
        "    # Set 'timestamp' as the index of the DataFrame\n",
        "    final_df.set_index('timestamp', inplace=True)\n",
        "\n",
        "    # Define a function to create a supervised learning dataset\n",
        "    def create_dataset(data, n_features):\n",
        "        X, y = [], []\n",
        "        for i in range(len(data)-n_features-1):\n",
        "            X.append(data[i:(i+n_features), 0])\n",
        "            y.append(data[i + n_features, 0])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    # Define the number of previous time steps to consider\n",
        "    n_steps = 30\n",
        "\n",
        "    # Create the supervised learning dataset\n",
        "    X, y = create_dataset(final_df.values, n_steps)\n",
        "\n",
        "    # Split the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    # Reshape the input data for LSTM\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "    # Define the RNN model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=(n_steps, 1)))\n",
        "    model.add(LSTM(50))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
        "\n",
        "    # Predict the log_valueTfuel after n_months_ahead\n",
        "    last_month_data = final_df.tail(n_steps).values\n",
        "    last_month_data = np.reshape(last_month_data, (1, n_steps, 1))\n",
        "\n",
        "    for _ in range(n_months_ahead):\n",
        "        predicted_value = model.predict(last_month_data)\n",
        "        last_month_data = np.append(last_month_data, np.expand_dims(predicted_value, axis=1), axis=1)\n",
        "        last_month_data = last_month_data[:, -n_steps:, :]\n",
        "\n",
        "    # Take anti-log to get the predicted value\n",
        "    predicted_value = np.expm1(predicted_value)\n",
        "\n",
        "    return predicted_value[0][0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "haibXRnJ8Jf1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "data_csv = 'data.csv'\n",
        "n_months_ahead = 1\n",
        "predicted_value = predict_value_after_months(data_csv, n_months_ahead)\n",
        "print(\"Predicted Value after\", n_months_ahead, \"month(s):\", predicted_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16Xs4WUb3y_o",
        "outputId": "3c93fd42-f231-472c-c50d-75d7ea431f72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 6s 42ms/step - loss: 54.1749\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 44.7526\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 35.8071\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 28.3265\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 22.4841\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 18.1221\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 14.7247\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 12.1933\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 9.9439\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 8.2983\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 6.9232\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 5.7646\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 5.0005\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 4.2957\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.8567\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.5924\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.3978\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.3391\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.3379\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.3686\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.4556\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.4746\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.4959\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.5068\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.5004\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.4860\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.4485\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.4410\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.3918\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3883\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.3573\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.3573\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.3446\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 3.3386\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 3.3361\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 3.3460\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.3406\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.3422\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.3433\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.3431\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.3428\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.3425\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.3418\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 3.3409\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.3423\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.3371\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 3.3413\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 3.3401\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.3404\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 3.3464\n",
            "1/1 [==============================] - 1s 766ms/step\n",
            "Predicted Value after 1 month(s): 1981.7373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nonIujR_31cJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "32Wzq-Xd2kQg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8P9oOGGy3wES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}